name: YouTube Movies Scraper

permissions:
  contents: write

on:
  workflow_dispatch:
  schedule:
    - cron: "0 7 * * 1"   # lundi 07:00 UTC

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0           # IMPORTANT (historique complet)
          persist-credentials: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper
        env:
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
          MAX_MOVIES_PER_RUN: "5"
        run: |
          python main.py

      - name: Debug - check repo state after script
        run: |
          echo "== FILES =="
          ls -la
          echo "== GIT STATUS =="
          git status
          echo "== SHOW GENERATED HEAD (first lines) =="
          head -n 3 comments.csv || true
          head -n 20 state.json || true

      - name: Commit & push results
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"

          # Ajouter fichiers générés (même si un jour tu les ignores)
          git add -f comments.csv state.json to_check_trailer.csv 2>/dev/null || true

          echo "== CACHED DIFF =="
          git diff --cached --stat || true

          # Si rien à commit -> stop
          git diff --cached --quiet && echo "No changes to commit" && exit 0

          git commit -m "Add generated data (comments/state)"
          git push origin HEAD:main
